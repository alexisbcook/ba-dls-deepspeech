{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_generator import DataGenerator\n",
    "\n",
    "train_desc_file = 'train_corpus.json'\n",
    "val_desc_file = 'validation_corpus.json'\n",
    "\n",
    "# Prepare the data generator\n",
    "datagen = DataGenerator()\n",
    "# Load the JSON file that contains the dataset\n",
    "datagen.load_train_data(train_desc_file)\n",
    "datagen.load_validation_data(val_desc_file)\n",
    "# Use a few samples from the dataset, to calculate the means and variance\n",
    "# of the features, so that we can center our inputs to the network\n",
    "datagen.fit_train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading description file: train_corpus_test.json for partition: train\n",
      "{\"duration\": 5.855, \"key\": \"LibriSpeech/train-clean-100/1272/128104/1272-128104-0000.wav\", \"text\": \"mister quilter is the apostle of the middle classes and we are glad to welcome his gospel\"}\n",
      "\n",
      "{\"duration\": 4.815, \"key\": \"LibriSpeech/train-clean-100/1272/128104/1272-128104-0001.wav\", \"text\": \"nor is mister quilter's manner less interesting than his matter\"}\n",
      "\n",
      "{\"duration\": 12.485, \"key\": \"LibriSpeech/train-clean-100/1272/128104/1272-128104-0002.wav\", \"text\": \"he tells us that at this festive season of the year with christmas and roast beef looming before us similes drawn from eating and its results occur most readily to the mind\"}\n",
      "\n",
      "{\"duration\": 9.9, \"key\": \"LibriSpeech/train-clean-100/1272/128104/1272-128104-0003.wav\", \"text\": \"he has grave doubts whether sir frederick leighton's work is really greek after all and can discover in it but little of rocky ithaca\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "desc_file = 'train_corpus_test.json'\n",
    "partition = 'train'\n",
    "max_duration = 10.0\n",
    "\n",
    "print('Reading description file: {} for partition: {}'\n",
    "                    .format(desc_file, partition))\n",
    "audio_paths, durations, texts = [], [], []\n",
    "with open(desc_file) as json_line_file:\n",
    "    for line_num, json_line in enumerate(json_line_file):\n",
    "        print(json_line)\n",
    "        try:\n",
    "            spec = json.loads(json_line)\n",
    "            if float(spec['duration']) > max_duration:\n",
    "                continue\n",
    "            audio_paths.append(spec['key'])\n",
    "            durations.append(float(spec['duration']))\n",
    "            texts.append(spec['text'])\n",
    "        except Exception as e:\n",
    "            print('Error reading line #{}: {}'\n",
    "                                .format(line_num, json_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'LibriSpeech/train-clean-100/1272/128104/1272-128104-0000.wav', u'LibriSpeech/train-clean-100/1272/128104/1272-128104-0001.wav', u'LibriSpeech/train-clean-100/1272/128104/1272-128104-0003.wav']\n",
      "[5.855, 4.815, 9.9]\n",
      "[u'mister quilter is the apostle of the middle classes and we are glad to welcome his gospel', u\"nor is mister quilter's manner less interesting than his matter\", u\"he has grave doubts whether sir frederick leighton's work is really greek after all and can discover in it but little of rocky ithaca\"]\n"
     ]
    }
   ],
   "source": [
    "print(audio_paths)\n",
    "print(durations)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import calc_feat_dim, spectrogram_from_file, text_to_int_sequence\n",
    "\n",
    "minibatch_size = 3\n",
    "k_iters = int(np.ceil(len(audio_paths) / minibatch_size))\n",
    "\n",
    "# featurize\n",
    "def featurize(audio_clip):\n",
    "    return spectrogram_from_file(audio_clip, step=10, window=20, max_freq=8000)\n",
    "\n",
    "# prepare_minibatch\n",
    "def prepare_minibatch(audio_paths, texts):\n",
    "    assert len(audio_paths) == len(texts),\\\n",
    "        \"Inputs and outputs to the network must be of the same number\"\n",
    "    features = [featurize(a) for a in audio_paths] # returns a list\n",
    "    input_lengths = [f.shape[0] for f in features]\n",
    "    max_length = max(input_lengths)\n",
    "    feature_dim = features[0].shape[1]\n",
    "    mb_size = len(features)\n",
    "    # Pad all the inputs so that they are all the same length\n",
    "    x = np.zeros((mb_size, max_length, feature_dim))\n",
    "    print(x.shape)\n",
    "    '''\n",
    "        y = []\n",
    "        label_lengths = []\n",
    "        for i in range(mb_size):\n",
    "            feat = features[i]\n",
    "            feat = self.normalize(feat)  # Center using means and std\n",
    "            x[i, :feat.shape[0], :] = feat\n",
    "            label = text_to_int_sequence(texts[i])\n",
    "            y.append(label)\n",
    "            label_lengths.append(len(label))\n",
    "        # Flatten labels to comply with warp-CTC signature\n",
    "        y = reduce(lambda i, j: i + j, y)\n",
    "        return {\n",
    "            'x': x,  # (0-padded features of shape(mb_size,timesteps,feat_dim)\n",
    "            'y': y,  # list(int) Flattened labels (integer sequences)\n",
    "            'texts': texts,  # list(str) Original texts\n",
    "            'input_lengths': input_lengths,  # list(int) Length of each input\n",
    "            'label_lengths': label_lengths  # list(int) Length of each label\n",
    "        }\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 989, 161)\n"
     ]
    }
   ],
   "source": [
    "prepare_minibatch(audio_paths, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import (BatchNormalization, Convolution1D, Dense, Input, GRU, TimeDistributed)\n",
    "from keras.models import Model\n",
    "\n",
    "input_dim=161 \n",
    "output_dim=29\n",
    "recur_layers=3 \n",
    "nodes=1024\n",
    "conv_context=11\n",
    "conv_border_mode='valid' \n",
    "conv_stride=2\n",
    "initialization='glorot_uniform' \n",
    "batch_norm=True\n",
    "\n",
    "acoustic_input = Input(shape=(None, input_dim), name='acoustic_input')\n",
    "\n",
    "    # Setup the network\n",
    "conv_1d = Convolution1D(nodes, conv_context, name='conv1d',\n",
    "                            border_mode=conv_border_mode,\n",
    "                            subsample_length=conv_stride, init=initialization,\n",
    "                            activation='relu')(acoustic_input)\n",
    "if batch_norm:\n",
    "    output = BatchNormalization(name='bn_conv_1d', mode=2)(conv_1d)\n",
    "else:\n",
    "    output = conv_1d\n",
    "\n",
    "for r in range(recur_layers):\n",
    "    output = GRU(nodes, activation='relu',\n",
    "                     name='rnn_{}'.format(r + 1), init=initialization,\n",
    "                     return_sequences=True)(output)\n",
    "    if batch_norm:\n",
    "        bn_layer = BatchNormalization(name='bn_rnn_{}'.format(r + 1),\n",
    "                                          mode=2)\n",
    "        output = bn_layer(output)\n",
    "\n",
    "# We don't softmax here because CTC does that\n",
    "network_output = TimeDistributed(Dense(\n",
    "    output_dim, name='dense', activation='linear', init=initialization))(output)\n",
    "model = Model(input=acoustic_input, output=network_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ctc\n",
    "import keras.backend as K\n",
    "import lasagne\n",
    "\n",
    "def compile_train_fn(model, learning_rate=2e-4):\n",
    "    # get input and output tensors\n",
    "    acoustic_input = model.inputs[0]\n",
    "    network_output = model.outputs[0]\n",
    "    # not sure ??\n",
    "    output_lens = K.placeholder(ndim=1, dtype='int32')\n",
    "    label = K.placeholder(ndim=1, dtype='int32')\n",
    "    label_lens = K.placeholder(ndim=1, dtype='int32')\n",
    "    # prep for CTC \n",
    "    network_output = network_output.dimshuffle((1, 0, 2))\n",
    "    # calculate CTC cost\n",
    "    ctc_cost = ctc.cpu_ctc_th(network_output, output_lens,\n",
    "                              label, label_lens).mean()\n",
    "    \n",
    "    # gradient // update stuff - not replicated in test version\n",
    "    trainable_vars = model.trainable_weights\n",
    "    grads = K.gradients(ctc_cost, trainable_vars)\n",
    "    grads = lasagne.updates.total_norm_constraint(grads, 100)\n",
    "    updates = lasagne.updates.nesterov_momentum(grads, trainable_vars,\n",
    "                                                learning_rate, 0.99)\n",
    "    \n",
    "    # not sure ...\n",
    "    train_fn = K.function([acoustic_input, output_lens, label, label_lens,\n",
    "                           K.learning_phase()],\n",
    "                          [network_output, ctc_cost],\n",
    "                          updates=updates)\n",
    "    return train_fn\n",
    "\n",
    "def compile_test_fn(model):\n",
    "    # get input and output tensors\n",
    "    acoustic_input = model.inputs[0]\n",
    "    network_output = model.outputs[0]\n",
    "    # not sure ??\n",
    "    output_lens = K.placeholder(ndim=1, dtype='int32')\n",
    "    label = K.placeholder(ndim=1, dtype='int32')\n",
    "    label_lens = K.placeholder(ndim=1, dtype='int32')\n",
    "    # prep for CTC\n",
    "    network_output = network_output.dimshuffle((1, 0, 2))\n",
    "    # calculate CTC cost\n",
    "    ctc_cost = ctc.cpu_ctc_th(network_output, output_lens,\n",
    "                              label, label_lens).mean()\n",
    "    # not sure\n",
    "    val_fn = K.function([acoustic_input, output_lens, label, label_lens,\n",
    "                        K.learning_phase()],\n",
    "                        [network_output, ctc_cost])\n",
    "    return val_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compile the CTC training function\n",
    "train_fn = compile_train_fn(model)\n",
    "# Compile the validation function\n",
    "val_fn = compile_test_fn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "mb_size = 16\n",
    "\n",
    "train_costs, val_costs = [], []\n",
    "iters = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    # sortagrad on first epoch, shuffle on all future epochs\n",
    "    shuffle = e != 0\n",
    "    sortagrad = e == 0\n",
    "\n",
    "    for i, batch in \\\n",
    "        enumerate(datagen.iterate_train(mb_size, shuffle=shuffle,\n",
    "                                        sort_by_duration=sortagrad)):\n",
    "        inputs = batch['x']\n",
    "        labels = batch['y']\n",
    "        input_lengths = batch['input_lengths']\n",
    "        label_lengths = batch['label_lengths']\n",
    "        # Due to convolution, the number of timesteps of the output\n",
    "        # is different from the input length. Calculate the resulting\n",
    "        # timesteps\n",
    "        output_lengths = [model.conv_output_length(l)\n",
    "                              for l in input_lengths]\n",
    "        _, ctc_cost = train_fn([inputs, output_lengths, labels,\n",
    "                                    label_lengths, True])\n",
    "        train_costs.append(ctc_cost)\n",
    "        if i % 10 == 0:\n",
    "                logger.info(\"Epoch: {}, Iteration: {}, Loss: {}\"\n",
    "                            .format(e, i, ctc_cost, input_lengths))\n",
    "            iters += 1\n",
    "            if iters % 500 == 0:\n",
    "                val_cost = validation(model, val_fn, datagen, mb_size)\n",
    "                val_costs.append(val_cost)\n",
    "                save_model(save_dir, model, train_costs, val_costs, iters)\n",
    "                \n",
    "    if iters % 500 != 0:\n",
    "        # End of an epoch. Check validation cost and save costs\n",
    "        val_cost = validation(model, val_fn, datagen, mb_size)\n",
    "        val_costs.append(val_cost)\n",
    "        save_model(save_dir, model, train_costs, val_costs, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
